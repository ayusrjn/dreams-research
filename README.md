# DREAMS Research Pipeline

Memory research pipeline for disentangled feature extraction from captured memories.

## Project Structure

```text
dreams-research/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”œâ”€â”€ user_01/          # Images organized by user
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ img_002.jpg
â”‚   â”‚   â”‚   â””â”€â”€ user_02/
â”‚   â”‚   â””â”€â”€ metadata.json         # All records with local image paths
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                # Phase 2 outputs
â”‚   â”‚   â”œâ”€â”€ image_embeddings.npy
â”‚   â”‚   â”œâ”€â”€ text_embeddings.npy
â”‚   â”‚   â”œâ”€â”€ emotion_scores.csv
â”‚   â”‚   â””â”€â”€ place_ids.csv
â”‚   â”‚
â”‚   â””â”€â”€ snapshots/                # Frozen experiment boundaries
â”‚       â””â”€â”€ snapshot_2026_01_25/
â”‚
â”œâ”€â”€ pipeline/                     # Processing scripts
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ pull_data.py
â”‚   â””â”€â”€ extract_image_embeddings.py
â”‚
â”œâ”€â”€ analysis/                     # Analysis notebooks
â””â”€â”€ README.md
```

## D1 Database Schema

| Column | Type | Description |
|--------|------|-------------|
| `id` | int | Primary key |
| `user_id` | string | User UUID |
| `caption` | string | Memory caption |
| `timestamp` | datetime | When memory was captured |
| `lat` | float | Latitude |
| `lon` | float | Longitude |
| `image_url` | string | Cloudinary URL |
| `processed` | int | 0 = unprocessed |
| `processing_version` | string | Pipeline version |
| `created_at` | datetime | DB insert time |

## Phase 1: Data Pull & Freezing

### Setup

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your Cloudflare D1 credentials
```

### Run

```bash
source .env
python pipeline/pull_data.py
```

### Output

After running:
- `data/raw/images/{user_id}/` - Downloaded images per user
- `data/raw/metadata.json` - All records with local paths
- `data/snapshots/snapshot_YYYY_MM_DD/` - Frozen copy

The snapshot is the **experiment boundary** for Phase 2.

---

## Phase 2A: Image Embeddings

Extracts CLIP (ViT-B/32) image embeddings from downloaded memories.

### Run

```bash
source venv/bin/activate
python pipeline/extract_image_embeddings.py
```

### Output

- `data/processed/image_embeddings.npy` - (N, 512) CLIP embeddings
- `data/processed/image_embedding_index.json` - Record ID to embedding index mapping

---

## Phase 2B: Caption Embeddings

Extracts Sentence-BERT (MiniLM) text embeddings from memory captions.

### Run

```bash
source venv/bin/activate
pip install sentence-transformers>=2.2.0
python pipeline/extract_caption_embeddings.py
```

### Output

- `data/processed/text_embeddings.npy` - (N, 384) Sentence-BERT embeddings
- `data/processed/caption_embedding_index.json` - Record ID to embedding index mapping

### Preprocessing Rules

- Unicode normalization (NFC)
- Strip leading/trailing whitespace
- Preserve punctuation and casing

---

## Phases Overview

| Phase | Description | Status |
|-------|-------------|--------|
| **Phase 1** | Data Pull & Freezing | âœ… Complete |
| **Phase 2A** | Image Embeddings (CLIP) | âœ… Complete |
| **Phase 2B** | Caption Embeddings (Sentence-BERT) | âœ… Complete |
| **Phase 2C** | Emotion Extraction | ðŸ”œ Planned |
| **Phase 2D** | Temporal Representation | ðŸ”œ Planned |
| **Phase 2E** | Location Clustering | ðŸ”œ Planned |
