# DREAMS Research Pipeline

Memory research pipeline for disentangled feature extraction from captured memories.

## Project Structure

```text
dreams-research/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”œâ”€â”€ user_01/          # Images organized by user
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ img_002.jpg
â”‚   â”‚   â”‚   â””â”€â”€ user_02/
â”‚   â”‚   â””â”€â”€ metadata.json         # All records with local image paths
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                # Phase 2 outputs
â”‚   â”‚   â”œâ”€â”€ image_embeddings.npy
â”‚   â”‚   â”œâ”€â”€ text_embeddings.npy
â”‚   â”‚   â”œâ”€â”€ emotion_scores.csv
â”‚   â”‚   â””â”€â”€ place_ids.csv
â”‚   â”‚
â”‚   â””â”€â”€ snapshots/                # Frozen experiment boundaries
â”‚       â””â”€â”€ snapshot_2026_01_25/
â”‚
â”œâ”€â”€ pipeline/                     # Processing scripts
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ pull_data.py
â”‚   â””â”€â”€ extract_image_embeddings.py
â”‚
â”œâ”€â”€ analysis/                     # Analysis notebooks
â””â”€â”€ README.md
```

## D1 Database Schema

| Column | Type | Description |
|--------|------|-------------|
| `id` | int | Primary key |
| `user_id` | string | User UUID |
| `caption` | string | Memory caption |
| `timestamp` | datetime | When memory was captured |
| `lat` | float | Latitude |
| `lon` | float | Longitude |
| `image_url` | string | Cloudinary URL |
| `processed` | int | 0 = unprocessed |
| `processing_version` | string | Pipeline version |
| `created_at` | datetime | DB insert time |

## Phase 1: Data Pull & Freezing

### Setup

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your Cloudflare D1 credentials
```

### Run

```bash
source .env
python pipeline/pull_data.py
```

### Output

After running:
- `data/raw/images/{user_id}/` - Downloaded images per user
- `data/raw/metadata.json` - All records with local paths
- `data/snapshots/snapshot_YYYY_MM_DD/` - Frozen copy

The snapshot is the **experiment boundary** for Phase 2.

---

## Phase 2A: Image Embeddings

Extracts CLIP (ViT-B/32) image embeddings from downloaded memories.

### Run

```bash
source venv/bin/activate
python pipeline/extract_image_embeddings.py
```

### Output

- `data/processed/image_embeddings.npy` - (N, 512) CLIP embeddings
- `data/processed/image_embedding_index.json` - Record ID to embedding index mapping

---

## Phase 2B: Caption Embeddings

Extracts Sentence-BERT (MiniLM) text embeddings from memory captions.

### Run

```bash
source venv/bin/activate
pip install sentence-transformers>=2.2.0
python pipeline/extract_caption_embeddings.py
```

### Output

- `data/processed/text_embeddings.npy` - (N, 384) Sentence-BERT embeddings
- `data/processed/caption_embedding_index.json` - Record ID to embedding index mapping

### Preprocessing Rules

- Unicode normalization (NFC)
- Strip leading/trailing whitespace
- Preserve punctuation and casing

---

## Phase 2C: Emotion Extraction

Extracts emotional features from captions using pretrained models:
- **Valence/Arousal**: Dimensional emotion (Mavdol/NPC-Valence-Arousal-Prediction)
- **Discrete Emotions**: Categorical probabilities (j-hartmann/emotion-english-distilroberta-base)

### Run

```bash
source venv/bin/activate
python pipeline/extract_emotions.py
```

### Output

- `data/processed/emotion_scores.csv` - Emotion features per record

### Columns

| Column | Description |
|--------|-------------|
| `id` | Unique record identifier |
| `user_id` | User identifier |
| `valence` | Pleasant (1) â†” Unpleasant (0) |
| `arousal` | High energy (1) â†” Low energy (0) |
| `joy` | Probability of joy |
| `sadness` | Probability of sadness |
| `fear` | Probability of fear |
| `anger` | Probability of anger |
| `neutral` | Probability of neutral |
| `disgust` | Probability of disgust |
| `surprise` | Probability of surprise |

> Emotion is an estimate of expressed affect, not internal state.

---

## Phase 2D: Temporal Representation

Extracts temporal features from timestamps for circadian and longitudinal analysis.

### Run

```bash
source venv/bin/activate
python pipeline/extract_temporal_features.py
```

### Output

- `data/processed/temporal_features.csv` - Temporal features per record

### Columns

| Column | Description |
|--------|-------------|
| `id` | Unique record identifier |
| `user_id` | User identifier |
| `absolute_utc` | ISO-8601 UTC timestamp |
| `relative_day` | Days since user's first entry |
| `sin_hour` | sin(2Ï€ Ã— hour / 24) - Circadian X coordinate |
| `cos_hour` | cos(2Ï€ Ã— hour / 24) - Circadian Y coordinate |

> Circadian encoding ensures 23:00 and 01:00 are mathematically close.

---

## Phases Overview

| Phase | Description | Status |
|-------|-------------|--------|
| **Phase 1** | Data Pull & Freezing | âœ… Complete |
| **Phase 2A** | Image Embeddings (CLIP) | âœ… Complete |
| **Phase 2B** | Caption Embeddings (Sentence-BERT) | âœ… Complete |
| **Phase 2C** | Emotion Extraction | âœ… Complete |
| **Phase 2D** | Temporal Representation | âœ… Complete |
| **Phase 2E** | Location Clustering | ðŸ”œ Planned |

